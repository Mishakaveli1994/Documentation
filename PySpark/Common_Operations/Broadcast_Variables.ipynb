{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# What are Broadcasted Variables\n",
    "In PySpark RDD and DataFrame, Broadcast variables are read-only shared variables that are cached and available\n",
    "on all nodes in a cluster in-order to access or use by the tasks. Instead of sending this data along with every task,\n",
    "PySpark distributes broadcast variables to the workers using efficient broadcast algorithms to\n",
    "reduce communication costs.\n",
    "\n",
    "## Use case\n",
    "\n",
    "Assume you are getting a two-letter country state code\n",
    "in a file and you wanted to transform it to full state name, (for example CA to California, NY to New York e.t.c)\n",
    "by doing a lookup to reference mapping. In some instances, this data could be large and you may have many such\n",
    "lookups (like zip code e.t.c).\n",
    "\n",
    "Instead of distributing this information along with each task over the network (overhead and time consuming), we\n",
    "can use the broadcast variable to cache this lookup info on each machine and tasks use this cached info while\n",
    " executing the transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# How does PySpark Broadcasting work\n",
    "Broadcast variables are used in the same way for RDD, DataFrame.\n",
    "When you run a PySpark RDD, DataFrame applications that have the Broadcast variables defined and used, PySpark does \n",
    "the following.\n",
    "\n",
    "PySpark breaks the job into stages that have distributed shuffling and actions are executed with in the stage.\n",
    "Later Stages are also broken into tasks\n",
    "Spark broadcasts the common data (reusable) needed by tasks within each stage.\n",
    "The broadcasted data is cache in serialized format and deserialized before executing each task.\n",
    "You should be creating and using broadcast variables for data that shared across multiple stages and tasks.\n",
    "\n",
    "Note that broadcast variables are not sent to executors with sc.broadcast(variable) call instead, they will be sent\n",
    " to executors when they are first used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to create RDD Broadcast Variables \n",
    "The PySpark Broadcast is created using the broadcast(v) method of the SparkContext class. This method takes \n",
    "the argument v that you want to broadcast.\n",
    "\n",
    "Below is a very simple example of how to use broadcast variables on RDD. This example defines commonly used data \n",
    "(states) in a Map variable and distributes the variable using SparkContext.broadcast() and then use these variables \n",
    "on RDD map() transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "states = {\"NY\": \"New York\", \"CA\": \"California\", \"FL\": \"Florida\"}\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "\n",
    "data = [(\"James\", \"Smith\", \"USA\", \"CA\"),\n",
    "        (\"Michael\", \"Rose\", \"USA\", \"NY\"),\n",
    "        (\"Robert\", \"Williams\", \"USA\", \"CA\"),\n",
    "        (\"Maria\", \"Jones\", \"USA\", \"FL\")\n",
    "        ]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]\n",
    "\n",
    "\n",
    "result = rdd.map(lambda x: (x[0], x[1], x[2], state_convert(x[3]))).collect()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# How to create Dataframe Broadcast Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below is an example of how to use broadcast variables on DataFrame, similar to above RDD example, this also uses \n",
    "commonly used data (states) in a Map variable and distributes the variable using SparkContext.broadcast() and \n",
    "then use these variables on DataFrame map() transformation.\n",
    "\n",
    "If you are not familiar with DataFrame, I will recommend to learn the DataFrame before proceeding further \n",
    "on this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]\n",
    "\n",
    "\n",
    "result = df.rdd.map(lambda x: (x[0], x[1], x[2], state_convert(x[3]))).toDF(columns)\n",
    "result.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Broadcast variables on filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filteDf = df.where((df['state'].isin(list(broadcastStates.value))))\n",
    "filteDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# How does PySpark Broadcasting work\n",
    "Broadcast variables are used in the same way for RDD, DataFrame.\n",
    "When you run a PySpark RDD, DataFrame applications that have the Broadcast variables defined and used, PySpark does \n",
    "the following.\n",
    "\n",
    "PySpark breaks the job into stages that have distributed shuffling and actions are executed with in the stage.\n",
    "Later Stages are also broken into tasks\n",
    "Spark broadcasts the common data (reusable) needed by tasks within each stage.\n",
    "The broadcasted data is cache in serialized format and deserialized before executing each task.\n",
    "You should be creating and using broadcast variables for data that shared across multiple stages and tasks.\n",
    "\n",
    "Note that broadcast variables are not sent to executors with sc.broadcast(variable) call instead, they will be sent\n",
    " to executors when they are first used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create RDD Broadcast Variables \n",
    "The PySpark Broadcast is created using the broadcast(v) method of the SparkContext class. This method takes \n",
    "the argument v that you want to broadcast.\n",
    "\n",
    "Below is a very simple example of how to use broadcast variables on RDD. This example defines commonly used data \n",
    "(states) in a Map variable and distributes the variable using SparkContext.broadcast() and then use these variables \n",
    "on RDD map() transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('James', 'Smith', 'USA', 'California'), ('Michael', 'Rose', 'USA', 'New York'), ('Robert', 'Williams', 'USA', 'California'), ('Maria', 'Jones', 'USA', 'Florida')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "states = {\"NY\": \"New York\", \"CA\": \"California\", \"FL\": \"Florida\"}\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "\n",
    "data = [(\"James\", \"Smith\", \"USA\", \"CA\"),\n",
    "        (\"Michael\", \"Rose\", \"USA\", \"NY\"),\n",
    "        (\"Robert\", \"Williams\", \"USA\", \"CA\"),\n",
    "        (\"Maria\", \"Jones\", \"USA\", \"FL\")\n",
    "        ]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]\n",
    "\n",
    "\n",
    "result = rdd.map(lambda x: (x[0], x[1], x[2], state_convert(x[3]))).collect()\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create Dataframe Broadcast Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how to use broadcast variables on DataFrame, similar to above RDD example, this also uses \n",
    "commonly used data (states) in a Map variable and distributes the variable using SparkContext.broadcast() and \n",
    "then use these variables on DataFrame map() transformation.\n",
    "\n",
    "If you are not familiar with DataFrame, I will recommend to learn the DataFrame before proceeding further \n",
    "on this article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|James    |Smith   |USA    |CA   |\n",
      "|Michael  |Rose    |USA    |NY   |\n",
      "|Robert   |Williams|USA    |CA   |\n",
      "|Maria    |Jones   |USA    |FL   |\n",
      "+---------+--------+-------+-----+\n",
      "\n",
      "+---------+--------+-------+----------+\n",
      "|firstname|lastname|country|state     |\n",
      "+---------+--------+-------+----------+\n",
      "|James    |Smith   |USA    |California|\n",
      "|Michael  |Rose    |USA    |New York  |\n",
      "|Robert   |Williams|USA    |California|\n",
      "|Maria    |Jones   |USA    |Florida   |\n",
      "+---------+--------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"firstname\", \"lastname\", \"country\", \"state\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]\n",
    "\n",
    "\n",
    "result = df.rdd.map(lambda x: (x[0], x[1], x[2], state_convert(x[3]))).toDF(columns)\n",
    "result.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcast variables on filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filteDf = df.where((df['state'].isin(list(broadcastStates.value))))\n",
    "filteDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
